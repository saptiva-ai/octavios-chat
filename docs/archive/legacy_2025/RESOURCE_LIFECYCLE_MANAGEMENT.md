# Resource Lifecycle Management

## Overview

Sistema completo de gesti√≥n del ciclo de vida de recursos para prevenir desbordamiento de memoria y optimizar el uso de storage en el sistema RAG de Capital 414.

## Problem√°tica

En sistemas RAG con m√∫ltiples usuarios y documentos, los recursos pueden crecer descontroladamente:

- **Redis**: Cache de chunks de texto puede consumir GB de RAM
- **Qdrant**: Vectores de embeddings ocupan espacio (384-dim √ó 4 bytes √ó N puntos)
- **MinIO**: Archivos originales (PDFs, im√°genes) acumulan GB de storage
- **MongoDB**: Metadata de documentos crece linealmente

**Sin gesti√≥n de lifecycle:**
- ‚ùå Memory leaks en Redis (cache nunca expira)
- ‚ùå Qdrant crece indefinidamente (vectores de sesiones antiguas)
- ‚ùå MinIO almacena archivos que nunca se volver√°n a usar
- ‚ùå Duplicados innecesarios (mismo PDF subido m√∫ltiples veces)

## Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Resource Lifecycle Manager (Singleton)               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ Deduplication‚îÇ  ‚îÇ  Monitoring  ‚îÇ  ‚îÇ   Cleanup    ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ   (SHA256)   ‚îÇ  ‚îÇ  (Metrics)   ‚îÇ  ‚îÇ   (Queue)    ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚Üì                   ‚Üì                   ‚Üì
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ  Redis   ‚îÇ      ‚îÇ  Qdrant  ‚îÇ       ‚îÇ  MinIO   ‚îÇ
  ‚îÇ  Cache   ‚îÇ      ‚îÇ  Vectors ‚îÇ       ‚îÇ  Storage ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   TTL: 1h           TTL: 24h           TTL: 7d
```

## Componentes

### 1. Resource Lifecycle Manager

**Ubicaci√≥n**: `apps/api/src/services/resource_lifecycle_manager.py`

**Responsabilidades:**
- ‚úÖ Deduplicaci√≥n de archivos (hash SHA256)
- ‚úÖ Monitoreo de uso de recursos
- ‚úÖ Limpieza autom√°tica de recursos obsoletos
- ‚úÖ Cola de prioridad para cleanup tasks

**Estrategia de Deduplicaci√≥n:**

```python
# Calcular hash SHA256 del archivo
file_hash = hashlib.sha256(file_content).hexdigest()

# Verificar si existe duplicado para el usuario
existing_doc = await Document.find_one({
    "metadata.file_hash": file_hash,
    "user_id": user_id
})

if existing_doc:
    # Reutilizar documento existente
    # Eliminar archivo reci√©n subido de MinIO
    return existing_doc.id
```

**Beneficios:**
- üöÄ Ahorra storage (no almacena duplicados)
- üöÄ Ahorra procesamiento (no re-extrae texto)
- üöÄ Respuesta instant√°nea (documento ya procesado)

### 2. Resource Cleanup Worker

**Ubicaci√≥n**: `apps/api/src/workers/resource_cleanup_worker.py`

**Background Tasks Concurrentes:**

| Task | Intervalo | Descripci√≥n |
|------|-----------|-------------|
| Redis Cleanup | 1 hora | Limpia keys sin TTL o expiradas |
| Qdrant Cleanup | 6 horas | Elimina vectores de sesiones antiguas (> 24h) |
| MinIO Cleanup | 24 horas | Elimina archivos no referenciados (> 7 d√≠as) |
| Resource Monitoring | 30 min | Monitorea uso y programa cleanup urgente |

**Arquitectura Asyncio:**

```python
class ResourceCleanupWorker:
    async def start(self):
        self.tasks = [
            asyncio.create_task(self._redis_cleanup_loop()),
            asyncio.create_task(self._qdrant_cleanup_loop()),
            asyncio.create_task(self._minio_cleanup_loop()),
            asyncio.create_task(self._monitoring_loop())
        ]

    async def stop(self):
        # Graceful shutdown
        for task in self.tasks:
            task.cancel()
        await asyncio.gather(*self.tasks, return_exceptions=True)
```

**Integraci√≥n con FastAPI:**

```python
# apps/api/src/main.py
@asynccontextmanager
async def lifespan(app: FastAPI):
    cleanup_worker = get_cleanup_worker()
    await cleanup_worker.start()

    yield

    await cleanup_worker.stop()
```

### 3. Resource Monitoring API

**Ubicaci√≥n**: `apps/api/src/routers/resources.py`

**Endpoints:**

#### GET /api/resources/metrics

Obtiene m√©tricas en tiempo real de todos los recursos.

**Response:**
```json
{
  "redis": {
    "total_items": 1250,
    "size_mb": 45.3,
    "usage_percentage": 17.7,
    "cleanup_priority": "LOW",
    "oldest_age_hours": 0.5
  },
  "qdrant": {
    "total_items": 33,
    "size_mb": 0.5,
    "usage_percentage": 0.03,
    "cleanup_priority": "LOW",
    "oldest_age_hours": 24.0
  },
  "minio": {
    "total_items": 12,
    "size_mb": 48.5,
    "usage_percentage": 0.09,
    "cleanup_priority": "LOW",
    "oldest_age_hours": 168.0
  },
  "mongodb": {
    "total_items": 12,
    "size_mb": 0.06,
    "usage_percentage": 0.12,
    "cleanup_priority": "LOW",
    "oldest_age_hours": 0
  }
}
```

#### POST /api/resources/cleanup

Trigger manual de limpieza.

**Request:**
```json
{
  "resource_type": "redis_cache"  // opcional: null = todos
}
```

**Response:**
```json
{
  "success": true,
  "deleted_counts": {
    "redis": 45,
    "qdrant": 0,
    "minio": 0
  },
  "message": "Cleanup completed. Total items deleted: 45"
}
```

#### GET /api/resources/queue

Estado de la cola de limpieza.

**Response:**
```json
{
  "queue_size": 2,
  "tasks": [
    {
      "priority": "HIGH",
      "resource_type": "qdrant_vectors",
      "target_id": "all",
      "created_at": "2025-01-20T15:30:00Z",
      "reason": "High resource usage: 78.5%"
    }
  ]
}
```

## Configuraci√≥n

### Variables de Entorno

Todas las configuraciones en `envs/.env`:

```bash
# ========================================
# RESOURCE LIFECYCLE MANAGEMENT
# ========================================

# TTLs (Time To Live)
REDIS_CACHE_TTL_HOURS=1              # Cache de chunks
RAG_SESSION_TTL_HOURS=24             # Vectores en Qdrant
FILES_TTL_DAYS=7                     # Archivos en MinIO

# Intervalos de limpieza (segundos)
REDIS_CLEANUP_INTERVAL_SECONDS=3600       # 1 hora
QDRANT_CLEANUP_INTERVAL_SECONDS=21600     # 6 horas
MINIO_CLEANUP_INTERVAL_SECONDS=86400      # 24 horas
RESOURCE_MONITORING_INTERVAL_SECONDS=1800 # 30 min

# Umbrales de uso (0.0 a 1.0)
CLEANUP_THRESHOLD_CRITICAL=0.9       # 90% - cleanup urgente
CLEANUP_THRESHOLD_HIGH=0.75          # 75% - alta prioridad
CLEANUP_THRESHOLD_MEDIUM=0.5         # 50% - prioridad media

# L√≠mites de recursos (soft limits)
MAX_REDIS_MEMORY_MB=256              # 256 MB
MAX_QDRANT_POINTS=100000             # 100k vectores
MAX_MINIO_STORAGE_GB=50              # 50 GB
```

### Pol√≠ticas de Retenci√≥n Recomendadas

#### Por Tipo de Aplicaci√≥n

**Aplicaci√≥n de Alta Rotaci√≥n (Capital 414):**
```bash
REDIS_CACHE_TTL_HOURS=1              # Cache corto
RAG_SESSION_TTL_HOURS=24             # Sesiones de un d√≠a
FILES_TTL_DAYS=7                     # Archivos de una semana
```

**Aplicaci√≥n de Largo Plazo (Archivo Hist√≥rico):**
```bash
REDIS_CACHE_TTL_HOURS=24             # Cache largo
RAG_SESSION_TTL_HOURS=168            # Sesiones de una semana
FILES_TTL_DAYS=365                   # Archivos de un a√±o
```

**Desarrollo/Testing:**
```bash
REDIS_CACHE_TTL_HOURS=0.5            # 30 minutos
RAG_SESSION_TTL_HOURS=2              # 2 horas
FILES_TTL_DAYS=1                     # 1 d√≠a
```

## Flujo de Limpieza

### 1. Limpieza Autom√°tica (Background)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Monitoring Loop (cada 30 min)                        ‚îÇ
‚îÇ    - Obtiene m√©tricas de todos los recursos             ‚îÇ
‚îÇ    - Calcula usage_percentage                           ‚îÇ
‚îÇ    - Asigna cleanup_priority (LOW/MEDIUM/HIGH/CRITICAL) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Scheduler (si priority >= HIGH)                      ‚îÇ
‚îÇ    - Agrega CleanupTask a cola de prioridad             ‚îÇ
‚îÇ    - Ordena por priority (menor = m√°s urgente)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Process Queue (cada 30 min)                          ‚îÇ
‚îÇ    - Procesa hasta 5 tareas de la cola                  ‚îÇ
‚îÇ    - Ejecuta cleanup_expired_resources()                ‚îÇ
‚îÇ    - Logs de items eliminados                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2. Limpieza Manual (via API)

```bash
# Ver m√©tricas actuales
curl http://localhost:8001/api/resources/metrics \
  -H "Authorization: Bearer $TOKEN"

# Trigger cleanup de Redis
curl -X POST http://localhost:8001/api/resources/cleanup \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"resource_type": "redis_cache"}'

# Ver cola de cleanup
curl http://localhost:8001/api/resources/queue \
  -H "Authorization: Bearer $TOKEN"
```

## Deduplicaci√≥n de Archivos

### Flujo de Upload con Deduplicaci√≥n

```
User uploads file
      ‚Üì
Compute SHA256 hash
      ‚Üì
Check database for duplicate (user_id + file_hash)
      ‚Üì
  ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ       ‚îÇ
FOUND    NOT FOUND
  ‚îÇ       ‚îÇ
  ‚îÇ       ‚îú‚îÄ‚îÄ Upload to MinIO
  ‚îÇ       ‚îú‚îÄ‚îÄ Store hash in metadata
  ‚îÇ       ‚îú‚îÄ‚îÄ Process (extract + chunk + embed)
  ‚îÇ       ‚îî‚îÄ‚îÄ Return new document ID
  ‚îÇ
  ‚îú‚îÄ‚îÄ Delete newly uploaded file from MinIO
  ‚îú‚îÄ‚îÄ Return existing document ID
  ‚îî‚îÄ‚îÄ Log: "Duplicate file detected"
```

### Beneficios Cuantificados

**Ejemplo: 100 usuarios, cada uno sube el mismo PDF 10 veces**

Sin deduplicaci√≥n:
- üìÅ Storage: 1000 archivos √ó 2 MB = 2 GB
- ‚öôÔ∏è Procesamiento: 1000 √ó 5 segundos = 83 minutos
- üíæ Qdrant: 1000 √ó 11 chunks √ó 1.5 KB = 16.5 MB

Con deduplicaci√≥n:
- üìÅ Storage: 100 archivos √ó 2 MB = 200 MB ‚úÖ **90% ahorro**
- ‚öôÔ∏è Procesamiento: 100 √ó 5 segundos = 8.3 minutos ‚úÖ **90% ahorro**
- üíæ Qdrant: 100 √ó 11 chunks √ó 1.5 KB = 1.65 MB ‚úÖ **90% ahorro**

## Monitoreo y Alertas

### M√©tricas Clave

**1. Usage Percentage**
- **Qu√© mide**: % de uso respecto al l√≠mite configurado
- **Umbral cr√≠tico**: > 90%
- **Acci√≥n**: Cleanup urgente autom√°tico

**2. Cleanup Priority**
- **LOW**: < 50% uso (sin acci√≥n)
- **MEDIUM**: 50-75% uso (monitoreo)
- **HIGH**: 75-90% uso (cleanup programado)
- **CRITICAL**: > 90% uso (cleanup inmediato)

**3. Oldest Item Age**
- **Qu√© mide**: Edad del recurso m√°s antiguo (horas)
- **Umbral**: > 2√ó TTL configurado
- **Acci√≥n**: Indica que cleanup no est√° funcionando

### Logs Estructurados

```json
{
  "event": "Resource monitoring completed",
  "metrics": {
    "redis": {"usage_percentage": 0.177, "priority": "LOW"},
    "qdrant": {"usage_percentage": 0.0003, "priority": "LOW"},
    "minio": {"usage_percentage": 0.009, "priority": "LOW"}
  },
  "timestamp": "2025-01-20T15:30:00Z"
}
```

```json
{
  "event": "Cleanup task processed",
  "resource_type": "qdrant_vectors",
  "priority": "HIGH",
  "deleted_count": 150,
  "reason": "High resource usage: 78.5%",
  "timestamp": "2025-01-20T15:35:00Z"
}
```

## Troubleshooting

### Problema: Uso de memoria creciendo constantemente

**Diagn√≥stico:**
```bash
# Ver m√©tricas
curl http://localhost:8001/api/resources/metrics -H "Authorization: Bearer $TOKEN" | jq .

# Verificar si cleanup worker est√° corriendo
docker logs octavios-chat-client-project-api | grep "ResourceCleanupWorker"
```

**Soluciones:**
1. **Worker no est√° iniciado**: Verificar `lifespan()` en `main.py`
2. **Intervalos muy largos**: Reducir `*_CLEANUP_INTERVAL_SECONDS`
3. **TTL muy largos**: Reducir `*_TTL_HOURS` / `*_TTL_DAYS`
4. **L√≠mites muy altos**: Reducir `MAX_*` variables

### Problema: Archivos duplicados no se detectan

**Diagn√≥stico:**
```bash
# Verificar que hash se est√° almacenando
db.documents.find({}, {"metadata.file_hash": 1, "filename": 1})
```

**Soluciones:**
1. **Hash no se almacena**: Verificar integraci√≥n en `file_ingest.py`
2. **Scope incorrecto**: Deduplicaci√≥n es por usuario (user_id + hash)
3. **Hash diferente**: Archivos con metadata diferente generan hash diferente

### Problema: Cleanup muy agresivo (elimina archivos activos)

**Diagn√≥stico:**
```bash
# Ver sesiones activas
db.chat_sessions.find({"updated_at": {$gte: new Date(Date.now() - 24*60*60*1000)}})
```

**Soluciones:**
1. **TTL muy corto**: Aumentar `FILES_TTL_DAYS`
2. **No verifica sesiones activas**: Revisar `_cleanup_minio_files()`
3. **Timestamp incorrecto**: Verificar `updated_at` en sesiones

## Best Practices

### 1. Configuraci√≥n por Entorno

**Development:**
```bash
# Limpieza agresiva para testing
REDIS_CACHE_TTL_HOURS=0.5
RAG_SESSION_TTL_HOURS=2
FILES_TTL_DAYS=1
REDIS_CLEANUP_INTERVAL_SECONDS=1800  # 30 min
```

**Production:**
```bash
# Balance entre disponibilidad y eficiencia
REDIS_CACHE_TTL_HOURS=1
RAG_SESSION_TTL_HOURS=24
FILES_TTL_DAYS=7
REDIS_CLEANUP_INTERVAL_SECONDS=3600  # 1 hora
```

### 2. Monitoreo Proactivo

```bash
# Cron job para alertas (cada 5 minutos)
*/5 * * * * curl -s http://localhost:8001/api/resources/metrics | \
  jq -r '.[] | select(.usage_percentage > 80) | "ALERT: \(.resource_type) at \(.usage_percentage)%"'
```

### 3. Cleanup Manual Peri√≥dico

```bash
# Script semanal de mantenimiento
#!/bin/bash
curl -X POST http://localhost:8001/api/resources/cleanup \
  -H "Authorization: Bearer $ADMIN_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"resource_type": null}'  # Limpia todo
```

### 4. Backup Antes de Cleanup

```bash
# Backup MongoDB antes de cleanup masivo
docker exec octavios-chat-client-project-mongodb mongodump --out /backup/$(date +%Y%m%d)

# Ejecutar cleanup
curl -X POST http://localhost:8001/api/resources/cleanup ...
```

## Arquitectura de Cola de Prioridad

### Estructura de CleanupTask

```python
@dataclass
class CleanupTask:
    priority: CleanupPriority    # 1=CRITICAL, 4=LOW
    resource_type: ResourceType  # redis/qdrant/minio
    target_id: str               # ID espec√≠fico o "all"
    created_at: datetime
    reason: str                  # "High resource usage: 85%"
```

### Algoritmo de Scheduling

```python
# 1. Monitoreo detecta uso alto
if usage_percentage >= 0.75:
    priority = CleanupPriority.HIGH

    # 2. Agrega a cola
    await manager.schedule_cleanup_task(
        resource_type=ResourceType.QDRANT_VECTORS,
        target_id="all",
        priority=priority,
        reason=f"High resource usage: {usage_percentage:.1%}"
    )

# 3. Cola se ordena autom√°ticamente por priority
cleanup_queue.sort(key=lambda t: t.priority.value)

# 4. Procesa tareas de mayor prioridad primero
while cleanup_queue and processed < max_tasks:
    task = cleanup_queue.pop(0)  # FIFO dentro de misma prioridad
    await cleanup_expired_resources(task.resource_type)
```

## Referencias

- [FastAPI Lifespan Events](https://fastapi.tiangolo.com/advanced/events/)
- [Asyncio Task Management](https://docs.python.org/3/library/asyncio-task.html)
- [Redis Memory Optimization](https://redis.io/docs/management/optimization/memory-optimization/)
- [Qdrant Collection Management](https://qdrant.tech/documentation/concepts/collections/)

## Changelog

- **v1.0** (2025-01-20): Implementaci√≥n inicial
  - Deduplicaci√≥n basada en SHA256
  - Background worker con 4 tasks concurrentes
  - API de monitoreo y cleanup manual
  - Pol√≠ticas de retenci√≥n configurables
