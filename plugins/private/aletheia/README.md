# Aletheia (·ºÄŒªŒÆŒ∏ŒµŒπŒ± - desocultamiento de la verdad)

Proyecto de deep research basado en modelos Saptiva y patrones AutoGen, con √©nfasis en veracidad, trazabilidad y despliegue soberano (cloud / on-prem / cliente).
---

## Alcance y Casos de Uso

Como usuario quiero usar la herramienta para:
- An√°lisis de una empresa
- An√°lisis macroecon√≥mico de un pa√≠s
- An√°lisis de una industria
- Benchmark (lista de competidores)
- Investigaci√≥n de un tema complejo (p. ej. ‚Äúc√≥mo implementar Triton en hardware AMD‚Äù)

**Criterios de Aceptaci√≥n (CA):**
- Se usan los modelos de **Saptiva**
- Se recibe un **reporte** consolidado con el resultado de investigaci√≥n
- C√≥digo documentado separando **b√∫squeda**, **planeaci√≥n** y **s√≠ntesis**
- Hay **traces** de consultas y de tools usadas (OpenTelemetry + event logs)
- **Tavily** se usa como motor de b√∫squeda primario (con fallback opcional)

---

## Arquitectura

En el centro vive el **Dominio** (agn√≥stico a framework/modelo). La orquestaci√≥n usa Saptiva‚ÄëAgents. Las dependencias externas entran por **Ports** y se implementan en **Adapters** intercambiables.

```mermaid
flowchart LR
  subgraph Domain[Dominio]
    T(ResearchTask)
Plan
Evidence
Citation
Report
    P[Planner]
R[Researcher]
C[Curator]
F[FactChecker]
W[Writer]
X[Critic]
  end

  subgraph Ports[Ports]
    MP[ModelClientPort]
    SP[SearchPort]
    VP[VectorStorePort]
    BP[BrowserPort]
    DP[DocExtractPort]
    GP[GuardPort]
    LP[LoggingPort]
    STP[StoragePort]
  end

  subgraph Adapters[Adapters]
    MA[Saptiva Model Client]
    TA[Tavily API]
    WA[Weaviate DB]
    SA[Multimodal Web Surfer]
    DA[PDF/OCR Extractor]
    GA[Saptiva Guard]
    OA[OpenTelemetry + Event Logs]
    FS[MinIO/S3/FS]
  end

  Domain --> Ports
  Ports --> Adapters
```

**Principios clave**
- **Separation of concerns:** Dominio no conoce Saptiva/Tavily; habla con puertos.
- **Configuraci√≥n por entorno:** cada adapter se resuelve por variables de entorno (on‚Äëprem, nube, cliente).
- **Observabilidad de primera clase:** todos los pasos emiten eventos estructurados y spans.
- **Reproducibilidad:** cada evidencia trae `source.url`, `excerpt`, `timestamp`, `hash` y `tool_call_id`.

---

## Equipo de Agentes (patrones al estilo AutoGen, implementados con Saptiva‚ÄëAgents)

| Rol | Modelo Saptiva sugerido | Tools/Ports | Funci√≥n |
|---|---|---|---|
| **Planner** | `Saptiva Ops` | Model, Vector, Search(meta) | Descompone la pregunta en sub‚Äëtareas, define presupuesto de pasos y criterios de cierre. |
| **Researcher** | `Saptiva Ops/Turbo` | **Tavily**, WebSurfer, DocExtract | Ejecuta b√∫squedas paralelas, lee p√°ginas/PDF, produce _evidence packs_. |
| **Curator (Evidence Scorer)** | `Saptiva Cortex` | Model | Deduplica, punt√∫a calidad (autoridad, frescura, consistencia), arma _top‚Äëk_. |
| **FactChecker** | `Saptiva Cortex` + **Guard** | Model, Guard | Cruza afirmaciones ‚Üî evidencias, aplica pol√≠ticas (PII, seguridad). |
| **Writer** | `Saptiva Cortex` | Model, Vector | Redacta **reporte** con citaciones \[1..N], tablas y anexos. |
| **Critic/Editor (Evaluation)** | `Saptiva Cortex` | Model | Eval√∫a completitud, identifica gaps, genera queries de refinamiento (Together AI pattern). |

> **Nota:** Dise√±o flexible para ejecutar como **Round‚ÄëRobin secuencial** o **fan‚Äëout concurrente** (Planner ‚Üí branch de Researchers por tipo de fuente ‚Üí merge en Curator).

---

## Flujo de Trabajo (patr√≥n Deep Research)

1. **Intake & Guard:** normaliza la pregunta, activa `Guard` y fija l√≠mites (pasos, tokens, dominios).
2. **Plan:** Planner entrega `research_plan.yaml` con sub‚Äëtareas y fuentes objetivo.
3. **B√∫squeda & Extracci√≥n:** Researcher usa **Tavily** (primario) + WebSurfer + Extractor PDF/OCR para obtener artefactos; cada artefacto se guarda con metadatos y hash.
4. **Indexado (RAG):** vectoriza con **Saptiva Embed** y guarda en **Weaviate** (colecci√≥n por _task_).
5. **Curaci√≥n:** Curator deduplica/scorea evidencias, produce `evidence_set.json` (top‚Äëk por sub‚Äëtarea).
6. **Borrador:** Writer redacta un primer reporte con citaciones \[i]‚Üíbibliograf√≠a.
7. **Verificaci√≥n (Reflection):** Critic/FactChecker marcan huecos; si aplica, se re‚Äëdispara b√∫squeda focalizada.
8. **Entrega:** genera **Markdown/HTML/PDF** y exporta **trazas** (spans + event logs + manifest de fuentes).

---

## Trazabilidad y Observabilidad

- **OpenTelemetry**: `TRACES_EXPORTER=otlp` (Jaeger/Zipkin soportados).
- **Event Logs**: cada herramienta emite `FunctionExecutionResult` con `args`, `elapsed_ms`, `excerpt` y `source.url`.
- **Run Manifest**: `runs/{task_id}/manifest.json` con versiones, semillas, presupuesto y checksums.
- **Replay:** se puede re‚Äëgenerar el informe desde `evidence_set.json` sin tocar la web (modo offline).

---

## Estructura del Repo

```
alethia/
‚îú‚îÄ apps/
‚îÇ  ‚îî‚îÄ api/                # FastAPI: /research, /reports/{id}, /traces/{id}
‚îú‚îÄ domain/
‚îÇ  ‚îú‚îÄ models/             # ResearchTask, Plan, Evidence, Citation, Report
‚îÇ  ‚îî‚îÄ services/           # PlannerSvc, ResearchSvc, CuratorSvc, WriterSvc
‚îú‚îÄ ports/                 # *Port interfaces (SearchPort, VectorStorePort, etc.)
‚îú‚îÄ adapters/
‚îÇ  ‚îú‚îÄ saptiva_model/      # SaptivaAIChatCompletionClient adapter
‚îÇ  ‚îú‚îÄ tavily_search/      # Tavily API adapter
‚îÇ  ‚îú‚îÄ weaviate_vector/    # VectorStore adapter (fallback: chroma/none)
‚îÇ  ‚îú‚îÄ web_surfer/         # Playwright/Multimodal surfer
‚îÇ  ‚îú‚îÄ extractor/          # PDF/OCR adapter
‚îÇ  ‚îú‚îÄ guard/              # Saptiva Guard adapter
‚îÇ  ‚îî‚îÄ telemetry/          # OTel & event logs
‚îú‚îÄ agents/                # Orquestaci√≥n Saptiva-Agents (team definitions)
‚îú‚îÄ prompts/               # System/prompts por rol (planner, writer, critic)
‚îú‚îÄ runs/                  # Artifacts por ejecuci√≥n (manifest, traces, evidence, report)
‚îî‚îÄ infra/
   ‚îú‚îÄ docker/             # Compose para dev; Jaeger/Weaviate/MinIO opcionales
   ‚îî‚îÄ k8s/                # Manifests para despliegues por entorno
```

---

## API (Implementada)

### Investigaci√≥n B√°sica (Secuencial)
- `POST /research`: body `{ query, scope, budget }` ‚Üí `202 Accepted` con `task_id`.
- `GET /reports/{task_id}`: devuelve `status`, `report.md`, `sources.bib`, `metrics.json`.
- `GET /traces/{task_id}`: descarga `manifest.json`, `events.ndjson`, `otel-export.json`.

### Deep Research (Together AI Pattern - Iterativo)
- `POST /deep-research`: body `{ query, scope, max_iterations, min_completion_score, budget }` ‚Üí `202 Accepted` con `task_id`.
- `GET /deep-research/{task_id}`: devuelve `status`, `report.md`, `sources.bib`, `research_summary`, `quality_metrics`.

**Esquema `Evidence` (resumen):**
```json
{
  "id": "ev_01",
  "source": {"url": "https://...", "title": "...", "fetched_at": "2025-09-10T20:00:00Z"},
  "excerpt": "p√°rrafo relevante...",
  "hash": "sha256:...",
  "tool_call_id": "tavily:search:abc123",
  "score": 0.84,
  "tags": ["macro", "2024", "imf"],
  "cit_key": "IMF2024"
}
```

---

## Variables de Entorno

### Configuraci√≥n Minimal (MVP)
```bash
# API Keys (obligatorias)
SAPTIVA_API_KEY=va-ai-xxxxx
SAPTIVA_BASE_URL=https://api.saptiva.com/v1
SAPTIVA_TIMEOUT=120
TAVILY_API_KEY=tvly-xxxxx

# Modelos (con espacios, sin comillas)
SAPTIVA_MODEL_PLANNER=Saptiva Ops
SAPTIVA_MODEL_WRITER=Saptiva Cortex

# Storage
ARTIFACTS_DIR=./runs

# Deshabilitar servicios opcionales
VECTOR_BACKEND=none
ENABLE_TELEMETRY=false
```

### Configuraci√≥n Full (Observabilidad)
```bash
# Agrega a configuraci√≥n minimal:
VECTOR_BACKEND=weaviate
WEAVIATE_HOST=http://localhost:8080
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
ENABLE_TELEMETRY=true
MINIO_ENDPOINT=minio:9000
```

### Configuraci√≥n Production
```bash
# Database
DATABASE_URL=postgresql://user:pass@postgres:5432/aletheia

# Cache
REDIS_URL=redis://:pass@redis:6379/0

# Object Storage
MINIO_ENDPOINT=minio:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=changeme123
MINIO_BUCKET=aletheia-artifacts

# Replicas
API_REPLICAS=2
```

---

## üèóÔ∏è Arquitecturas Disponibles

### üì¶ Opci√≥n A: **Minimal** (Recomendado para MVP/Development)
Solo API + Saptiva + Tavily. Sin dependencias extras.

```yaml
Stack:
‚úÖ API FastAPI
‚úÖ Saptiva AI (LLM)
‚úÖ Tavily Search
‚úÖ Filesystem storage
```

**Ventajas:**
- ‚ö° Setup en 30 segundos
- üéØ Enfoque en valor core
- üí∞ ~300MB RAM
- üßπ C√≥digo simple

### üì¶ Opci√≥n B: **Full** (Con observabilidad)
API + servicios de infraestructura opcionales.

```yaml
Stack:
‚úÖ API FastAPI
‚úÖ Saptiva AI + Tavily
‚úÖ Weaviate (opcional - RAG)
‚úÖ Jaeger (tracing)
‚úÖ MinIO (storage)
```

### üì¶ Opci√≥n C: **Production** (Escalable)
Stack completo para producci√≥n.

```yaml
Stack:
‚úÖ API FastAPI (multi-replica)
‚úÖ PostgreSQL (persistencia)
‚úÖ Redis (cache/queue)
‚úÖ MinIO/S3 (artifacts)
‚úÖ Weaviate (RAG)
‚úÖ Jaeger (observabilidad)
‚úÖ Nginx (load balancer)
```

---

## üöÄ Quickstart

### Opci√≥n 1: Docker Minimal (Recomendado para MVP)

```bash
# 1. Clonar el repositorio
git clone <repo-url>
cd alethia_deepresearch

# 2. Configurar variables de entorno
cp .env.example .env
# Edita .env y agrega tus API keys:
# - SAPTIVA_API_KEY (obtener en https://lab.saptiva.com)
# - TAVILY_API_KEY (obtener en https://tavily.com)

# 3. Levantar solo la API (sin dependencias)
docker-compose -f infra/docker/docker-compose.minimal.yml up -d

# 4. Verificar que est√© corriendo
docker logs -f aletheia-api-minimal

# 5. Hacer una investigaci√≥n
curl -X POST "http://localhost:8000/research" \
  -H "Content-Type: application/json" \
  -d '{"query":"An√°lisis competitivo de bancos digitales en M√©xico 2024"}'

# 6. Obtener el reporte (reemplaza TASK_ID con el ID que te devuelve el paso anterior)
curl "http://localhost:8000/reports/TASK_ID"
```

### Opci√≥n 2: Docker Full (Con observabilidad)

```bash
# 1. Configurar .env
cp .env.example .env
# Edita .env con tus API keys

# 2. Levantar stack completo (API + Weaviate + Jaeger + MinIO)
docker-compose -f infra/docker/docker-compose.yml up -d

# 3. Verificar servicios
docker-compose -f infra/docker/docker-compose.yml ps

# 4. Acceder a UIs
# - API Docs: http://localhost:8000/docs
# - Jaeger Traces: http://localhost:16686
# - MinIO Console: http://localhost:9000
```

### Opci√≥n 3: Docker Production (Escalable)

```bash
# 1. Configurar .env.production
cp .env.example .env.production
# Edita con configuraci√≥n de producci√≥n (PostgreSQL, Redis, etc.)

# 2. Levantar stack de producci√≥n
docker-compose -f infra/docker/docker-compose.production.yml up -d

# 3. Verificar r√©plicas de API
docker-compose -f infra/docker/docker-compose.production.yml ps api

# 4. Acceder a trav√©s de Nginx
curl http://localhost/research
```

### Opci√≥n 4: Desarrollo local

```bash
# 1. Crear entorno virtual
python -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Configurar .env
cp .env.example .env
# Edita .env con tus API keys

# 4. (Opcional) Levantar servicios de infraestructura
docker-compose -f infra/docker/docker-compose.yml up -d weaviate jaeger minio

# 5. Ejecutar API
uvicorn apps.api.main:app --reload --port 8000

# 6. Hacer investigaci√≥n
curl -X POST "http://localhost:8000/research" \
  -H "Content-Type: application/json" \
  -d '{"query":"Tu pregunta de investigaci√≥n"}'
```

### üîó URLs de Servicios (seg√∫n arquitectura)

**Minimal:**
- **API Aletheia**: http://localhost:8000
- **API Docs (Swagger)**: http://localhost:8000/docs

**Full:**
- **API Aletheia**: http://localhost:8000
- **API Docs (Swagger)**: http://localhost:8000/docs
- **Weaviate (Vector DB)**: http://localhost:8080
- **Jaeger (Tracing)**: http://localhost:16686
- **MinIO (Storage)**: http://localhost:9000 (user: minioadmin, pass: minioadmin)

**Production:**
- **API Aletheia**: http://localhost (a trav√©s de Nginx)
- **API Docs**: http://localhost/docs
- **Jaeger UI**: http://localhost:16686
- **MinIO Console**: http://localhost:9001

### üìä Monitoreo

```bash
# Minimal: Ver logs de la API
docker logs -f aletheia-api-minimal

# Full/Production: Ver logs de todos los servicios
docker-compose -f infra/docker/docker-compose.yml logs -f

# Ver traces en Jaeger (Full/Production)
open http://localhost:16686

# Ver m√©tricas de recursos
docker stats
```

---

## Decisiones de Dise√±o

- **Hexagonal / Ports & Adapters**: permite reemplazar Tavily por otro motor o Weaviate por Pinecone sin tocar dominio.
- **Tavily por defecto**: resultados limpios y API simple; si falla, fallback a Google CSE/WebSurfer.
- **Weaviate**: buena opci√≥n **on‚Äëprem**; embeddings con **Saptiva Embed**.
- **Reflection**: Writer ‚Üî Critic con m√°ximo N iteraciones y presupuesto de tokens.
- **Defensa ante alucinaciones**: _grounding_ obligado: toda afirmaci√≥n factual debe trazar a `Evidence.id`.
- **Costo/latencia**: l√≠mites por etapa, caching de queries y memoizaci√≥n de embeddings.

---

## Seguridad y Cumplimiento

- **Guard** en _input_ y _output_; lista de dominios permitidos opcional.
- **PII redaction** previa a persistencia de artefactos.
- **Determinismo relativo**: registrar seeds/temperatures y versiones de modelos.

---

## Roadmap y Estado Actual

### ‚úÖ v0.2.1 (COMPLETADO) - Simplificaci√≥n y Multi-Architecture
- **Arquitectura Flexible:** 3 configuraciones (Minimal/Full/Production) seg√∫n necesidades
- **Minimal MVP:** API funcional sin dependencias complejas (Weaviate/MinIO opcionales)
- **Vector Store Opcional:** ResearchService con `enable_vector_store=False` por defecto
- **Writer Simplificado:** Removida RAG in√∫til que buscaba en colecci√≥n reci√©n creada
- **Docker Compose Multi-Tier:** Minimal (MVP), Full (observabilidad), Production (escalable)
- **Correcciones Cr√≠ticas:** Saptiva API URL, timeout 120s, weaviate-client v4

### ‚úÖ v0.2 (COMPLETADO) - Together AI Deep Research Pattern
- **Patrones Avanzados:** Implementaci√≥n completa del patr√≥n Together AI con agentes Saptiva
- **Investigaci√≥n Iterativa:** Sistema multi-iteraci√≥n con evaluaci√≥n y refinamiento autom√°tico
- **API Completa:** Endpoints `/research` y `/deep-research` operativos con Tavily API integrada
- **Agente Evaluador:** Assessment autom√°tico de completitud y identificaci√≥n de gaps

### üéØ Funcionalidades Clave Operativas:
- ‚úÖ **Planner Agent** (SAPTIVA_OPS): Genera planes de investigaci√≥n estructurados
- ‚úÖ **Research Agent** (TAVILY + Saptiva): B√∫squeda web real con 15+ fuentes por query
- ‚úÖ **Evaluation Agent** (SAPTIVA_CORTEX): Scoring de completitud y an√°lisis de gaps
- ‚úÖ **Writer Agent** (SAPTIVA_CORTEX): Generaci√≥n de reportes con citaciones
- ‚úÖ **Iterative Orchestrator**: Loop inteligente hasta alcanzar calidad objetivo

### üöÄ Casos de Uso Validados:
```bash
# Investigaci√≥n b√°sica (secuencial)
curl -X POST "http://localhost:8000/research" \
  -H "Content-Type: application/json" \
  -d '{"query": "An√°lisis competitivo bancos digitales M√©xico 2024"}'

# Deep Research (iterativo con Together AI pattern)
curl -X POST "http://localhost:8000/deep-research" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "An√°lisis estrat√©gico mercado fintech M√©xico 2024", 
    "max_iterations": 3,
    "min_completion_score": 0.75,
    "budget": 150
  }'
```

### üìä M√©tricas de Calidad Implementadas:
- **Completion Score**: 0.0-1.0 scale con niveles (insufficient/partial/adequate/comprehensive)
- **Coverage Areas**: Scoring granular por √°reas de investigaci√≥n
- **Gap Analysis**: Identificaci√≥n autom√°tica de informaci√≥n faltante
- **Iterative Refinement**: Queries de seguimiento inteligentes

### üèóÔ∏è v0.3 (Pr√≥ximo) - DevOps & Production Ready
- **CI/CD Pipeline**: GitHub Actions con testing automatizado
- **Branching Strategy**: Git Flow con feature branches y releases
- **Testing Suite**: Unit tests + integration tests + end-to-end
- **Containerizaci√≥n**: Docker multi-stage builds optimizados
- **Monitoring**: M√©tricas de performance y alerting
- **Security**: Vulnerability scanning y secret management

### üìã v1.0 (Futuro)
- **Concurrencia Avanzada**: Parallel search agents y async processing
- **WebSurfer Multimodal**: Extracci√≥n de im√°genes y PDFs
- **UI Dashboard**: Interface web para monitoring y control
- **Export Avanzado**: PDF/HTML con gr√°ficos y visualizaciones
- **Kubernetes**: Helm charts para despliegue en producci√≥n

---

## Licencia
MIT (propuesta).
